{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow import keras\n",
        "\n",
        "# The batch size we'll use for training\n",
        "batch_size = 64\n",
        "\n",
        "# Size of the image required to train our model\n",
        "img_size = 120\n",
        "\n",
        "# These many images will be used from the data archive\n",
        "dataset_split = 2500\n",
        "\n",
        "# Directory where your images are stored (replace 'data' with your actual directory path)\n",
        "master_dir = '/content/images'\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "\n",
        "# Loop over the images in the directory\n",
        "for image_file in os.listdir(master_dir)[:dataset_split]:\n",
        "    # Construct the full image path\n",
        "    image_path = os.path.join(master_dir, image_file)\n",
        "\n",
        "    # Open and resize the image to the required size (120x120)\n",
        "    rgb_image = Image.open(image_path).resize((img_size, img_size))\n",
        "\n",
        "    # Normalize the RGB image array\n",
        "    rgb_img_array = np.asarray(rgb_image) / 255.0\n",
        "\n",
        "    # Convert to grayscale and resize the image\n",
        "    gray_image = rgb_image.convert('L')\n",
        "    gray_img_array = np.asarray(gray_image).reshape((img_size, img_size, 1)) / 255.0\n",
        "\n",
        "    # Append both the image arrays\n",
        "    x.append(gray_img_array)\n",
        "    y.append(rgb_img_array)\n",
        "\n",
        "# Train-test splitting (90% training, 10% testing)\n",
        "train_x, test_x, train_y, test_y = train_test_split(np.array(x), np.array(y), test_size=0.1)\n",
        "\n",
        "# Construct tf.data.Dataset object\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
        "dataset = dataset.batch(batch_size)\n",
        "\n",
        "# Optional: You can add dataset for testing as well\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
        "test_dataset = test_dataset.batch(batch_size)\n",
        "\n",
        "# Check the size of the dataset\n",
        "print(f\"Number of training samples: {len(train_x)}\")\n",
        "print(f\"Number of test samples: {len(test_x)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVMOR46ccFf3",
        "outputId": "06ff23ad-7ede-46e2-d209-83a535686816"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 665\n",
            "Number of test samples: 74\n",
            "Number of training samples: 665\n",
            "Number of test samples: 74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_generator_model():\n",
        "\n",
        "    inputs = tf.keras.layers.Input( shape=( img_size , img_size , 1 ) )\n",
        "\n",
        "    conv1 = tf.keras.layers.Conv2D( 16 , kernel_size=( 5 , 5 ) , strides=1 )( inputs )\n",
        "    conv1 = tf.keras.layers.LeakyReLU()( conv1 )\n",
        "    conv1 = tf.keras.layers.Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=1)( conv1 )\n",
        "    conv1 = tf.keras.layers.LeakyReLU()( conv1 )\n",
        "    conv1 = tf.keras.layers.Conv2D( 32 , kernel_size=( 3 , 3 ) , strides=1)( conv1 )\n",
        "    conv1 = tf.keras.layers.LeakyReLU()( conv1 )\n",
        "\n",
        "    conv2 = tf.keras.layers.Conv2D( 32 , kernel_size=( 5 , 5 ) , strides=1)( conv1 )\n",
        "    conv2 = tf.keras.layers.LeakyReLU()( conv2 )\n",
        "    conv2 = tf.keras.layers.Conv2D( 64 , kernel_size=( 3 , 3 ) , strides=1 )( conv2 )\n",
        "    conv2 = tf.keras.layers.LeakyReLU()( conv2 )\n",
        "    conv2 = tf.keras.layers.Conv2D( 64 , kernel_size=( 3 , 3 ) , strides=1 )( conv2 )\n",
        "    conv2 = tf.keras.layers.LeakyReLU()( conv2 )\n",
        "\n",
        "    conv3 = tf.keras.layers.Conv2D( 64 , kernel_size=( 5 , 5 ) , strides=1 )( conv2 )\n",
        "    conv3 = tf.keras.layers.LeakyReLU()( conv3 )\n",
        "    conv3 = tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1 )( conv3 )\n",
        "    conv3 = tf.keras.layers.LeakyReLU()( conv3 )\n",
        "    conv3 = tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1 )( conv3 )\n",
        "    conv3 = tf.keras.layers.LeakyReLU()( conv3 )\n",
        "\n",
        "    bottleneck = tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1 , activation='tanh' , padding='same' )( conv3 )\n",
        "\n",
        "    concat_1 = tf.keras.layers.Concatenate()( [ bottleneck , conv3 ] )\n",
        "    conv_up_3 = tf.keras.layers.Conv2DTranspose( 128 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' )( concat_1 )\n",
        "    conv_up_3 = tf.keras.layers.Conv2DTranspose( 128 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' )( conv_up_3 )\n",
        "    conv_up_3 = tf.keras.layers.Conv2DTranspose( 64 , kernel_size=( 5 , 5 ) , strides=1 , activation='relu' )( conv_up_3 )\n",
        "\n",
        "    concat_2 = tf.keras.layers.Concatenate()( [ conv_up_3 , conv2 ] )\n",
        "    conv_up_2 = tf.keras.layers.Conv2DTranspose( 64 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' )( concat_2 )\n",
        "    conv_up_2 = tf.keras.layers.Conv2DTranspose( 64 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu' )( conv_up_2 )\n",
        "    conv_up_2 = tf.keras.layers.Conv2DTranspose( 32 , kernel_size=( 5 , 5 ) , strides=1 , activation='relu' )( conv_up_2 )\n",
        "\n",
        "    concat_3 = tf.keras.layers.Concatenate()( [ conv_up_2 , conv1 ] )\n",
        "    conv_up_1 = tf.keras.layers.Conv2DTranspose( 32 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu')( concat_3 )\n",
        "    conv_up_1 = tf.keras.layers.Conv2DTranspose( 32 , kernel_size=( 3 , 3 ) , strides=1 , activation='relu')( conv_up_1 )\n",
        "    conv_up_1 = tf.keras.layers.Conv2DTranspose( 3 , kernel_size=( 5 , 5 ) , strides=1 , activation='relu')( conv_up_1 )\n",
        "\n",
        "    model = tf.keras.models.Model( inputs , conv_up_1 )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "Kgj96jbIkZnI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_discriminator_model():\n",
        "    layers = [\n",
        "        tf.keras.layers.Conv2D( 32 , kernel_size=( 7 , 7 ) , strides=1 , activation='relu' , input_shape=( 120 , 120 , 3 ) ),\n",
        "        tf.keras.layers.Conv2D( 32 , kernel_size=( 7, 7 ) , strides=1, activation='relu'  ),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Conv2D( 64 , kernel_size=( 5 , 5 ) , strides=1, activation='relu'  ),\n",
        "        tf.keras.layers.Conv2D( 64 , kernel_size=( 5 , 5 ) , strides=1, activation='relu'  ),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1, activation='relu'  ),\n",
        "        tf.keras.layers.Conv2D( 128 , kernel_size=( 3 , 3 ) , strides=1, activation='relu'  ),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=1, activation='relu'  ),\n",
        "        tf.keras.layers.Conv2D( 256 , kernel_size=( 3 , 3 ) , strides=1, activation='relu'  ),\n",
        "        tf.keras.layers.MaxPooling2D(),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense( 512, activation='relu'  )  ,\n",
        "        tf.keras.layers.Dense( 128 , activation='relu' ) ,\n",
        "        tf.keras.layers.Dense( 16 , activation='relu' ) ,\n",
        "        tf.keras.layers.Dense( 1 , activation='sigmoid' )\n",
        "    ]\n",
        "    model = tf.keras.models.Sequential( layers )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "URtrxjChkg8z"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
        "mse = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output) - tf.random.uniform( shape=real_output.shape , maxval=0.1 ) , real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output) + tf.random.uniform( shape=fake_output.shape , maxval=0.1  ) , fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "\n",
        "def generator_loss(fake_output , real_y):\n",
        "    real_y = tf.cast( real_y , 'float32' )\n",
        "    return mse( fake_output , real_y )\n",
        "\n",
        "generator_optimizer = tf.keras.optimizers.Adam( 0.0005 )\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam( 0.0005 )\n",
        "\n",
        "generator = get_generator_model()\n",
        "discriminator = get_discriminator_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HkQhViFbkkyT",
        "outputId": "d479934c-47ac-46cc-d71c-8dfd3608f950"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step( input_x , real_y ):\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        # Generate an image -> G( x )\n",
        "        generated_images = generator( input_x , training=True)\n",
        "        # Probability that the given image is real -> D( x )\n",
        "        real_output = discriminator( real_y, training=True)\n",
        "        # Probability that the given image is the one generated -> D( G( x ) )\n",
        "        generated_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        # L2 Loss -> || y - G(x) ||^2\n",
        "        gen_loss = generator_loss( generated_images , real_y )\n",
        "        # Log loss for the discriminator\n",
        "        disc_loss = discriminator_loss( real_output, generated_output )\n",
        "\n",
        "    #tf.keras.backend.print_tensor( tf.keras.backend.mean( gen_loss ) )\n",
        "    #tf.keras.backend.print_tensor( gen_loss + disc_loss )\n",
        "\n",
        "    # Compute the gradients\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    # Optimize with Adam\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n"
      ],
      "metadata": {
        "id": "NV3ok-OZkqGr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 2\n",
        "\n",
        "for e in range( num_epochs ):\n",
        "    print( e )\n",
        "    for ( x , y ) in dataset:\n",
        "        # Here ( x , y ) represents a batch from our training dataset.\n",
        "        print( x.shape )\n",
        "        train_step( x , y )\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv8X0iJmkrNl",
        "outputId": "8919cbe3-4f91-4502-b218-a7034d663a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "(64, 120, 120, 1)\n",
            "(64, 120, 120, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = generator( test_x[0 : ] ).numpy()"
      ],
      "metadata": {
        "id": "9feHThbOktmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(test_x)):\n",
        "  plt.figure(figsize=(10,10))\n",
        "  or_image = plt.subplot(3,3,1)\n",
        "  or_image.set_title('Grayscale Input', fontsize=16)\n",
        "  plt.imshow( test_x[i].reshape((120,120)) , cmap='gray' )\n",
        "\n",
        "  in_image = plt.subplot(3,3,2)\n",
        "  image = Image.fromarray( ( y[i] * 255 ).astype( 'uint8' ) ).resize( ( 1024 , 1024 ) )\n",
        "  image = np.asarray( image )\n",
        "  in_image.set_title('Colorized Output', fontsize=16)\n",
        "  plt.imshow( image )\n",
        "\n",
        "  ou_image = plt.subplot(3,3,3)\n",
        "  image = Image.fromarray( ( test_y[i] * 255 ).astype( 'uint8' ) ).resize( ( 1024 , 1024 ) )\n",
        "  ou_image.set_title('Ground Truth', fontsize=16)\n",
        "  plt.imshow( image )\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "NhVhK0L7kyNG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}